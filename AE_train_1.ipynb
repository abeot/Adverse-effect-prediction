{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hqom9ivNOkjq",
        "outputId": "a0a54394-173a-4816-a132-23cfcf59edd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.3.0\n",
            "cuda:  False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print('cuda: ', torch.cuda.is_available())\n",
        "\n",
        "## CONSTANTS\n",
        "lr = 1e-5 # learning rate, try 1e-5\n",
        "wd = 1e-5 # weight decay try 1e-5\n",
        "best_epoch = 0\n",
        "MAX_EPOCH = 300\n",
        "\n",
        "# BELOW IS NOT CHANGEABLE\n",
        "in_dim = 215\n",
        "# best_cohen = 0.19\n",
        "k_folds = 5\n",
        "\n",
        "# model_path = f'test_{ae_name}.pt'\n",
        "\n",
        "patience = 5\n",
        "verbose_freq = 100 # print out results every 10 epochs\n",
        "\n",
        "best_cohen_dict  = {\n",
        "    'diarrhoea': 0.273,\n",
        "    'dizziness': 0.31,\n",
        "    'headache': 0.3187,\n",
        "    'nausea': 0.2935,\n",
        "    'vomiting': 0.27\n",
        "}\n",
        "params = {'batch_size':64, 'shuffle':False,\n",
        "              'drop_last':False, 'num_workers': 0}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6zYEnL4O3_y"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HatwBwXaM9gV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from utils import *\n",
        "\n",
        "def normalize(df):\n",
        "    result = df.copy()\n",
        "    for feature_name in df.columns:\n",
        "        max_value = df[feature_name].max()\n",
        "        min_value = df[feature_name].min()\n",
        "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
        "    return result\n",
        "\n",
        "def get_data(ae_name, negative_sampling=None):\n",
        "    df = pd.read_csv(f'data_normalized_{ae_name}.csv')\n",
        "    df = df.drop(columns=['drug', 'SMILES'])\n",
        "    # df = normalize(df)\n",
        "    from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "    split = StratifiedShuffleSplit(n_splits=5, test_size=0.15, random_state=42)\n",
        "    for train_index, test_index in split.split(df, df[ae_name]):\n",
        "        train_df = df.loc[train_index]\n",
        "        test_df = df.loc[test_index]\n",
        "\n",
        "    if negative_sampling != None:\n",
        "        counts = train_df[ae_name].value_counts()\n",
        "        print('previous:', counts)\n",
        "        count_0 = counts[0]\n",
        "        count_1 = counts[1]\n",
        "        negative_df = train_df.loc[train_df[ae_name] == 0]\n",
        "        while count_0 < count_1*negative_sampling:\n",
        "            train_df = pd.concat([train_df, negative_df], ignore_index=True)\n",
        "            counts = train_df[ae_name].value_counts()\n",
        "            count_0 = counts[0]\n",
        "            count_1 = counts[1]\n",
        "        print('After adding negative samples', counts)\n",
        "    return df, train_df, test_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PruMXSK6-Ifm"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, in_dim, h_dims:list):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        neurons = [in_dim, *h_dims]\n",
        "        linear_layers = [nn.Linear(neurons[i-1], neurons[i]) \\\n",
        "                         for i in range(1, len(neurons))]\n",
        "        self.hidden = nn.ModuleList(linear_layers)\n",
        "        # self.emb = nn.GRU(h_dims[-1], h_dims[-1])\n",
        "        self.final = nn.Linear(h_dims[-1], 1)\n",
        "        self.output = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.hidden:\n",
        "            x = F.relu(layer(x))\n",
        "        # x = torch.squeeze(self.output(self.final(x)))\n",
        "        x = torch.squeeze(self.output(self.final(x)))\n",
        "        return x\n",
        "\n",
        "class tox_dataset(Dataset):\n",
        "    def __init__(self, df, ae_name):\n",
        "        self.len = len(df)\n",
        "        self.df = df\n",
        "        self.ic_start_ind = df.columns.get_loc(\"appendix endocrine cells\")\n",
        "        self.ae_start_ind = df.columns.get_loc(ae_name)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        OUTPUT\n",
        "        :param fp: fingerprint, should be 167 dim\n",
        "        :param ic: drug tissue concentration\n",
        "        :param ae: adverse events\n",
        "        \"\"\"\n",
        "        # header = ['bit' + str(i) for i in range(167)]\n",
        "        # fp = self.df[header]\n",
        "        # fp = torch.tensor([float(b) for b in fp.iloc[idx]], dtype=torch.float32)\n",
        "        ic = self.df.iloc[:, self.ic_start_ind:self.ae_start_ind]\n",
        "        ic = torch.tensor(ic.values.astype(np.float32))[idx]\n",
        "        ae = self.df.iloc[:, self.ae_start_ind:]\n",
        "        ae = torch.tensor(ae.values.astype(np.float32))[idx]\n",
        "        # ae = onehot(5)(ae) # use onehot\n",
        "        # return fp, ic, ae.float()\n",
        "        return ic, ae.float()\n",
        "    def __len__(self): return self.len\n",
        "\n",
        "def loss_func(output, target, weight):\n",
        "\n",
        "    target = target.to(dtype=torch.float32)\n",
        "\n",
        "    output.requires_grad_(True)\n",
        "    target.requires_grad_(True)\n",
        "\n",
        "    log_output = torch.log(torch.clamp(output, min=1e-10, max=1.0 - 1e-10))\n",
        "    log_1_minus_output = torch.log(torch.clamp(1 - output,\n",
        "                                    min=1e-10, max=1.0 - 1e-10))\n",
        "\n",
        "    loss = -torch.sum(target * log_output + \\\n",
        "            weight * (1 - target) * log_1_minus_output)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def train_epoch(model, loader, device='cpu', epoch=None, optimizer=None,\n",
        "                MASK=-100, model_type='MLP', weight_loss=None, ver=False, ae_name=\"\"):\n",
        "    if optimizer==None: # no optimizer, either valid or test\n",
        "        model.eval()\n",
        "        if epoch != None: train_type = 'Valid'\n",
        "        else: train_type = 'Test'\n",
        "    else: model.train(); train_type='Train'\n",
        "\n",
        "    if weight_loss == None:\n",
        "        weight_loss = 1.0\n",
        "    total_loss, y_probs, y_label = 0, {}, {}\n",
        "\n",
        "    for idx, batch_data in enumerate(loader):\n",
        "        # fp, ic, ae = batch_data\n",
        "        # fp, ic, ae = fp.to(device), ic.to(device), ae.to(device)\n",
        "        ic, ae = batch_data\n",
        "        ic, ae = ic.to(device), ae.to(device)\n",
        "        mask = ae == MASK\n",
        "        mask = mask.to(device)\n",
        "        # pred = model(torch.cat((fp, ic), 1))\n",
        "        pred = model(ic)\n",
        "        # print('pred', pred)\n",
        "\n",
        "        loss = loss_func(pred, ae, weight_loss)\n",
        "\n",
        "        if train_type != 'Train': # valid or test, output probs and labels\n",
        "            probs = pred.cpu().detach().numpy().tolist()\n",
        "            label = ae.cpu().detach().numpy().tolist()\n",
        "            # print(probs, type(probs), label, type(label))\n",
        "            if isinstance(probs, float): probs = [probs]\n",
        "            if isinstance(label, float): label = [label]\n",
        "            if idx == 0: y_probs, y_label = probs, label\n",
        "            else: y_probs += probs; y_label += label\n",
        "\n",
        "        total_loss += loss.item() # sum up all loss for all AE in this batch\n",
        "        # print(total_loss)\n",
        "        if optimizer != None:\n",
        "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
        "\n",
        "    total_loss /= len(loader)\n",
        "    if epoch != None: # train or valid\n",
        "        if ver: print(f'Epoch:{epoch}, [{train_type}] loss: {total_loss:.3f}')\n",
        "    elif epoch == None: # test\n",
        "        if ver: print(f'[{train_type}] loss: {total_loss:.3f}')\n",
        "        # print(y_probs, y_label)\n",
        "        performance = eval_dict(y_probs, y_label, False,\n",
        "                                'MLP', draw_fig=True, ae_name=ae_name)\n",
        "        # performance = float(total_loss)\n",
        "\n",
        "    if   train_type == 'Train': return total_loss, y_probs, y_label\n",
        "    elif train_type == 'Valid': return total_loss, y_probs, y_label\n",
        "    else: return performance, y_probs, y_label\n",
        "\n",
        "def load_model(model, path, device='cpu'):\n",
        "    print('load model from path: ', path)\n",
        "    model.load_state_dict(torch.load(path, map_location=device))\n",
        "\n",
        "def eval(model, loader, path=None, ae_name=\"\", device='cpu'):\n",
        "    if path != None: load_model(model, path)\n",
        "    performance, probs, label = train_epoch(model, loader, device=device, ae_name=ae_name)\n",
        "    return performance, probs, label\n",
        "\n",
        "\n",
        "from dgllife.utils import EarlyStopping\n",
        "\n",
        "\n",
        "\n",
        "def train(model, data_loader, val_loader, test_loader=None, weight_loss=None,\n",
        "          ver_freq=verbose_freq, optimizer=None, ae_name=\"\", device='cuda', model_path=None):\n",
        "    train_dict = {}\n",
        "    valid_dict = {}\n",
        "    min_loss = np.inf\n",
        "    if model_path == None: model_path = f'test_{ae_name}.pt'\n",
        "\n",
        "    ### MOD:\n",
        "    # stopper was put inside function train instead of outside.\n",
        "    # Otherwise you are using the same stopper for 5-fold validation\n",
        "    stopper = EarlyStopping(mode='lower', patience=patience)\n",
        "\n",
        "\n",
        "    for epoch in range(best_epoch, MAX_EPOCH):\n",
        "        score, _, _ = train_epoch(model, data_loader, epoch=epoch,\n",
        "                optimizer=optimizer, weight_loss=weight_loss, device=device)\n",
        "        val_score, probs, labels = train_epoch(model, val_loader,\n",
        "                epoch=epoch, weight_loss=weight_loss, device=device)\n",
        "        print(f'Epoch:{epoch} [Train] Loss:{score:.3f} | ',\n",
        "              f'[Valid] Loss: {val_score:.3f}', end='\\t')\n",
        "        train_dict[epoch] = score\n",
        "        valid_dict[epoch] = val_score\n",
        "\n",
        "        early_stop = stopper.step(val_score, model)\n",
        "        if val_score < min_loss:\n",
        "            print(f'SAVE MODEL: loss drop: {min_loss:.3f} -> {val_score:.3f}')\n",
        "            min_loss = val_score\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "\n",
        "        if epoch % ver_freq == 0 and epoch != 0:\n",
        "            plot_loss(train_dict, valid_dict, name='valid',\n",
        "            title_name=\"loss during training MLP\")\n",
        "            eval_dict(probs, labels, False, 'MLP', ae_name=ae_name)\n",
        "\n",
        "        if early_stop: print('early stop'); break\n",
        "\n",
        "    print('Finished training \\n')\n",
        "    # clean_files() # delete all .pth files, use with caution\n",
        "\n",
        "    plot_loss(train_dict, valid_dict, name='valid',\n",
        "            title_name=\"loss during training MLP\")\n",
        "\n",
        "    if test_loader != None:\n",
        "        performance, _, _ = eval(model, test_loader, model_path,\n",
        "                                 device=device, ae_name=ae_name)\n",
        "        return performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DItY66tJ6zYY"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from dgllife.utils import EarlyStopping\n",
        "from sklearn.model_selection import KFold\n",
        "import pickle\n",
        "# hidden dims of neural network are changeable,\n",
        "# as long as its all integers\n",
        "# h_dims = [400*2, 256*2, 128*2, 128, 64]\n",
        "\n",
        "def get_max(d:dict):\n",
        "    max_key = next(iter(d))\n",
        "    for key in d:\n",
        "        if d[key] > d[max_key]: max_key = key\n",
        "    return max_key, d[max_key]\n",
        "\n",
        "\n",
        "def batch_train(ae_name, model_file, k_folds,\n",
        "                min_weight, max_weight, weight_interval,\n",
        "                negative_sampling=None, best_cohen=0.15, batch_size=64):\n",
        "\n",
        "    _, train_df, test_df = get_data(ae_name, negative_sampling=negative_sampling)\n",
        "\n",
        "    with open(f'{model_file}/h_dims.pkl', 'rb') as f: h_dims = pickle.load(f)\n",
        "\n",
        "    temp_min = int(min_weight/weight_interval)\n",
        "    temp_max = int(max_weight/weight_interval)\n",
        "    kf = KFold(n_splits=k_folds, shuffle=True)\n",
        "\n",
        "    model_path = f'{model_file}/test_{ae_name}.pt'\n",
        "\n",
        "    train_dataset = tox_dataset(train_df, ae_name)\n",
        "    params = {'batch_size':batch_size, 'shuffle':False,\n",
        "              'drop_last':False, 'num_workers': 0}\n",
        "    test_loader = DataLoader(tox_dataset(test_df, ae_name), **params)\n",
        "\n",
        "    # weight_losses = [0.2, 8.0, 8.0, 7.0, 6.0]\n",
        "\n",
        "    result_dict = {}\n",
        "\n",
        "    for idx_here in range(temp_min, temp_max):\n",
        "        print('\\n\\n')\n",
        "        weight_loss_here = idx_here * weight_interval\n",
        "        print('*'*40, weight_loss_here, '*'*40)\n",
        "\n",
        "        result_list = []\n",
        "\n",
        "        for repeat_time in range(3):\n",
        "\n",
        "            results = {\n",
        "                \"acc\": [],\n",
        "                \"precision\": [],\n",
        "                \"recall\": [],\n",
        "                \"F1\": [],\n",
        "                \"TP\": [],\n",
        "                \"TN\": [],\n",
        "                \"FP\": [],\n",
        "                \"FN\": [],\n",
        "                \"cohen\": []\n",
        "            }\n",
        "            for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
        "                print(f\"Fold {fold + 1}/{k_folds}, batch_size={batch_size},\", end=\"\")\n",
        "                print(f\"negative sampling={negative_sampling}, weight {weight_loss_here}, {ae_name}, {model_file}\")\n",
        "                print(\"-------\")\n",
        "\n",
        "                stopper = EarlyStopping(mode='lower', patience=patience)\n",
        "                train_loader = DataLoader(\n",
        "                    train_dataset,\n",
        "                    batch_size=batch_size,\n",
        "                    sampler=torch.utils.data.SubsetRandomSampler(train_idx),\n",
        "                )\n",
        "                val_loader = DataLoader(\n",
        "                    train_dataset,\n",
        "                    batch_size=batch_size,\n",
        "                    sampler=torch.utils.data.SubsetRandomSampler(val_idx),\n",
        "                )\n",
        "\n",
        "                model = Classifier(in_dim, h_dims)\n",
        "                if torch.cuda.is_available(): model = model.cuda()\n",
        "                optimizer = optim.AdamW(params=model.parameters(),\n",
        "                                        lr=lr, weight_decay=wd)\n",
        "\n",
        "                cls_results = train(model, train_loader, val_loader, test_loader,\n",
        "                        weight_loss=weight_loss_here, optimizer=optimizer,\n",
        "                        ae_name=ae_name, device='cuda', model_path=model_path)\n",
        "                # _, probs, label = eval(model, test_loader, model_path, device='cuda')\n",
        "                # preds = get_preds(0.5, probs)\n",
        "                # cls_results = evaluate(label, preds, probs)\n",
        "                # print('cls_results:', cls_results)\n",
        "                cohen_here = cls_results['cohen']\n",
        "                if cohen_here > best_cohen:\n",
        "                    try: file_old_path = file_new_path\n",
        "                    except: file_old_path = 'not_find_this_file'\n",
        "                    print('save model, best cohen by now =', cohen_here)\n",
        "                    file_new_path = f'{model_file}/{ae_name}_cohen_{cohen_here}.pt'\n",
        "                    torch.save(model.state_dict(), file_new_path)\n",
        "                    import os\n",
        "                    file_path = f'{ae_name}_cohen_{best_cohen}.pt'\n",
        "                    if os.path. exists(file_old_path):\n",
        "                        os.remove(file_old_path)\n",
        "                        print(f\"The file {file_old_path} has been deleted.\")\n",
        "                    best_cohen = cohen_here\n",
        "\n",
        "                # [ACCURACY, weighted_accuracy, precision, SE, SP, F1, AUC, MCC, AP]\n",
        "                for key in cls_results:\n",
        "                    results[key].append(cls_results[key])\n",
        "\n",
        "                # if cls_results['cohen'] == 0:\n",
        "                #     break\n",
        "            for key in results:\n",
        "                results[key].append(np.mean(results[key]))\n",
        "\n",
        "            results_df = pd.DataFrame.from_dict(results)\n",
        "            cohen_here = results_df['cohen'].tolist()[-1]\n",
        "            result_list.append(cohen_here)\n",
        "            if cohen_here == 0: break\n",
        "\n",
        "        result_dict[weight_loss_here] = sum(result_list) / len(result_list)\n",
        "        if result_dict[weight_loss_here] < 0: break\n",
        "\n",
        "        # argmax_cohen, max_cohen = get_max(result_dict)\n",
        "        # if len(result_dict) > argmax_cohen + 3: break\n",
        "\n",
        "    # clean_files()\n",
        "    return result_dict\n",
        "# results_df.to_csv(f\"{ae_name}_results.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9GC1CaBO9ow"
      },
      "source": [
        "## Experiment (Do not run, cost several days)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xDhusFQXYJuE"
      },
      "outputs": [],
      "source": [
        "# h_dims = [1600, 1028, 512, 216, 128]\n",
        "# model_file = 'best_models_3'\n",
        "# import pickle\n",
        "# # model_file = 'best_models_1'\n",
        "# with open(f'{model_file}/h_dims.pkl', 'wb') as f: pickle.dump(h_dims, f)\n",
        "# with open(f'{model_file}/h_dims.pkl', 'rb') as f: h_dims = pickle.load(f)\n",
        "# h_dims\n",
        "\n",
        "clean_files()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "w3DQYAErUzLs"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'best_models/h_dims.pkl'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m ae_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdizziness\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvomiting\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiarrhoea\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     15\u001b[0m                 \u001b[38;5;66;03m# for ae_name in ['vomiting']:\u001b[39;00m\n\u001b[1;32m     16\u001b[0m                     best_cohen \u001b[38;5;241m=\u001b[39m best_cohen_dict[ae_name]\n\u001b[0;32m---> 17\u001b[0m                     result_dict \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mae_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_folds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mmin_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mnegative_sampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_cohen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_cohen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#                     if result_dict != None:\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#                         break\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#                 break\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#     break\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# result_dict\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[5], line 22\u001b[0m, in \u001b[0;36mbatch_train\u001b[0;34m(ae_name, model_file, k_folds, min_weight, max_weight, weight_interval, negative_sampling, best_cohen, batch_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_train\u001b[39m(ae_name, model_file, k_folds,\n\u001b[1;32m     17\u001b[0m                 min_weight, max_weight, weight_interval,\n\u001b[1;32m     18\u001b[0m                 negative_sampling\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, best_cohen\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.15\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m):\n\u001b[1;32m     20\u001b[0m     _, train_df, test_df \u001b[38;5;241m=\u001b[39m get_data(ae_name, negative_sampling\u001b[38;5;241m=\u001b[39mnegative_sampling)\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_file\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/h_dims.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f: h_dims \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     24\u001b[0m     temp_min \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(min_weight\u001b[38;5;241m/\u001b[39mweight_interval)\n\u001b[1;32m     25\u001b[0m     temp_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(max_weight\u001b[38;5;241m/\u001b[39mweight_interval)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best_models/h_dims.pkl'"
          ]
        }
      ],
      "source": [
        "best_cohen_dict  = {\n",
        "    'diarrhoea': 0.273,\n",
        "    'dizziness': 0.31,\n",
        "    'headache': 0.3187,\n",
        "    'nausea': 0.29357,\n",
        "    'vomiting': 0.27748\n",
        "}\n",
        "\n",
        "for model_file in ['best_models', 'best_models_3', 'best_models_2', 'best_models_1']:\n",
        "    for k_folds in range(5, 10):\n",
        "        k_folds = int(k_folds)\n",
        "        for batch_size in [64]:\n",
        "            for ns in [None, 0.1, 0.2, 0.3]:\n",
        "                for ae_name in ['dizziness', 'vomiting','diarrhoea']:\n",
        "                # for ae_name in ['vomiting']:\n",
        "                    best_cohen = best_cohen_dict[ae_name]\n",
        "                    result_dict = batch_train(ae_name, model_file, k_folds,\n",
        "                                min_weight=0.5, max_weight=9, weight_interval=0.5,\n",
        "                                negative_sampling=ns, best_cohen=best_cohen,\n",
        "                                batch_size=batch_size)\n",
        "#                     if result_dict != None:\n",
        "#                         break\n",
        "#                 break\n",
        "#             break\n",
        "#         break\n",
        "#     break\n",
        "# result_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YumkVgGRxF3N"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "model_file = 'best_models_2'\n",
        "\n",
        "# h_dims = [400, 256, 128, 64]\n",
        "\n",
        "# h_dims =  [200, 128, 64, 32]\n",
        "# import pickle\n",
        "# # model_file = 'best_models_1'\n",
        "# with open(f'{model_file}/h_dims.pkl', 'wb') as f: pickle.dump(h_dims, f)\n",
        "# with open(f'{model_file}/h_dims.pkl', 'rb') as f: h_dims = pickle.load(f)\n",
        "# h_dims\n",
        "\n",
        "for i in tqdm(range(9,1,-1), desc=f'current'):\n",
        "    max_weight = min(int(10/i) + 3, 9)\n",
        "    min_weight = max(min(max(int(10/i) - 3, 1), max_weight-4), 0.2)\n",
        "    # print('min max:', min_weight, max_weig)ht)\n",
        "    for _, ae_name in tqdm(enumerate(['headache', 'nausea', 'vomiting', 'dizziness', 'diarrhoea']), total=5, desc=f'current ae, i= {i}'):\n",
        "        result_dict = batch_train(ae_name, model_file, k_folds,\n",
        "                            min_weight=min_weight, max_weight=max_weight,\n",
        "                            weight_interval=0.2,\n",
        "                            negative_sampling=0.1*i, best_cohen=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Tqx3aa2nVky"
      },
      "outputs": [],
      "source": [
        "for i in range(1,10):\n",
        "    # max_weight = min(int(10/i) + 3, 9)\n",
        "    # min_weight = max(min(max(int(10/i) - 3, 1), max_weight-4), 0.2)\n",
        "    max_weight = 9\n",
        "    min_weight = 1\n",
        "    print('min max:', min_weight, max_weight)\n",
        "    for ae_name in ['dizziness']:\n",
        "        result_dict = batch_train(ae_name, model_file, k_folds,\n",
        "                            min_weight=min_weight, max_weight=max_weight,\n",
        "                            weight_interval=0.2,\n",
        "                            negative_sampling=0.1*i, best_cohen=0.00001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAo2qXhrYOsz"
      },
      "outputs": [],
      "source": [
        "# for i in range(1,10):\n",
        "#     max_weight = min(int(10/i) + 3, 9)\n",
        "#     min_weight = max(min(max(int(10/i) - 3, 1), max_weight-4), 0.2)\n",
        "#     print('min max:', min_weight, max_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE5tIRKtS3PM"
      },
      "source": [
        "## Results\n",
        "\n",
        "Parameter tested:\n",
        "\n",
        "* h_dims:  \n",
        "  \n",
        "```\n",
        "  [1000, 512, 256, 128] - folder 'best_models'\n",
        "\n",
        "  [400, 256, 128, 64].  - folder 'best_models_1'\n",
        "\n",
        "  [200, 128, 64, 32]    - folder 'best_models_2'\n",
        "```\n",
        "\n",
        "* negative sampling 0.1 - 1, increment = 0. 1\n",
        "\n",
        "* loss_weight, 1-9, increment = 0.2\n",
        "\n",
        "---> further possible solution\n",
        "\n",
        "* k_folds, 2-10, increment = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnyqAI4P8sLj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5x9n_BLTc5K"
      },
      "outputs": [],
      "source": [
        "clean_files()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxYgoa5JYPSv"
      },
      "outputs": [],
      "source": [
        "# ae_name = 'diarrhoea'\n",
        "# acc\t   precision\trecall\t     F1\t       TP\t    TN\tFP\tFN\t cohen\n",
        "# 0.929577\t0.927536\t1.000000\t0.962406\t64.0\t2.0\t5.0\t0.0\t0.418985"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m2AFSvIsX96x",
        "outputId": "30bfe5c9-d787-4521-8688-194c161b1272"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'h_dims' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m      5\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(tox_dataset(test_df, ae_name), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# with open(f'{model_folder}/h_dims.pkl', 'rb') as f: h_dims = pickle.load(f)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# print(h_dims)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m model \u001b[38;5;241m=\u001b[39m Classifier(in_dim, \u001b[43mh_dims\u001b[49m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available(): model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     14\u001b[0m model_path_best_cohen \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/Adverse-effect-prediction-main/best_models_2/diarrhoea_cohen_0.2736572890025576.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'h_dims' is not defined"
          ]
        }
      ],
      "source": [
        "model_folder = 'best_models_2'\n",
        "ae_name = 'diarrhoea'\n",
        "\n",
        "_, _, test_df = get_data(ae_name)\n",
        "test_loader = DataLoader(tox_dataset(test_df, ae_name), **params)\n",
        "\n",
        "\n",
        "# with open(f'{model_folder}/h_dims.pkl', 'rb') as f: h_dims = pickle.load(f)\n",
        "# print(h_dims)\n",
        "\n",
        "\n",
        "model = Classifier(in_dim, h_dims)\n",
        "if torch.cuda.is_available(): model = model.cuda()\n",
        "model_path_best_cohen = '/content/drive/MyDrive/Adverse-effect-prediction-main/best_models_2/diarrhoea_cohen_0.2736572890025576.pt'\n",
        "\n",
        "# def eval(model, loader, path=None, device='cpu'):\n",
        "#     if path != None: load_model(model, path)\n",
        "#     performance, probs, label = train_epoch(model, loader, device=device)\n",
        "#     return performance, probs, label\n",
        "\n",
        "_ = eval(model, test_loader, path=model_path_best_cohen, device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "80YwRx1HPjmc",
        "outputId": "f3470755-2eef-4ef3-c0f9-fb3c59c768d6"
      },
      "outputs": [],
      "source": [
        "model_folder = 'best_models'\n",
        "ae_name = 'dizziness'\n",
        "\n",
        "_, _, test_df = get_data(ae_name)\n",
        "test_loader = DataLoader(tox_dataset(test_df, ae_name), **params)\n",
        "with open(f'{model_folder}/h_dims.pkl', 'rb') as f: h_dims = pickle.load(f)\n",
        "\n",
        "model = Classifier(in_dim, h_dims)\n",
        "if torch.cuda.is_available(): model = model.cuda()\n",
        "model_path_best_cohen = '/content/drive/MyDrive/Adverse-effect-prediction-main/best_models/dizziness_cohen_0.3109869646182495.pt'\n",
        "\n",
        "# def eval(model, loader, path=None, device='cpu'):\n",
        "#     if path != None: load_model(model, path)\n",
        "#     performance, probs, label = train_epoch(model, loader, device=device)\n",
        "#     return performance, probs, label\n",
        "\n",
        "_ = eval(model, test_loader, path=model_path_best_cohen, device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "Hg_SKq26PlmS",
        "outputId": "961bb612-98a6-4bba-af31-dd22e2895787"
      },
      "outputs": [],
      "source": [
        "model_folder = 'best_models'\n",
        "ae_name = 'headache'\n",
        "\n",
        "_, _, test_df = get_data(ae_name)\n",
        "test_loader = DataLoader(tox_dataset(test_df, ae_name), **params)\n",
        "with open(f'{model_folder}/h_dims.pkl', 'rb') as f: h_dims = pickle.load(f)\n",
        "\n",
        "model = Classifier(in_dim, h_dims)\n",
        "if torch.cuda.is_available(): model = model.cuda()\n",
        "model_path_best_cohen = '/content/drive/MyDrive/Adverse-effect-prediction-main/best_models/headache_cohen_0.4108761329305136.pt'\n",
        "\n",
        "# def eval(model, loader, path=None, device='cpu'):\n",
        "#     if path != None: load_model(model, path)\n",
        "#     performance, probs, label = train_epoch(model, loader, device=device)\n",
        "#     return performance, probs, label\n",
        "\n",
        "_ = eval(model, test_loader, path=model_path_best_cohen, device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "P7gi7QLgPrA7",
        "outputId": "4e9fce07-0195-49c5-f8e0-6dd6692a5a1d"
      },
      "outputs": [],
      "source": [
        "model_folder = 'best_models'\n",
        "ae_name = 'nausea'\n",
        "\n",
        "_, _, test_df = get_data(ae_name)\n",
        "test_loader = DataLoader(tox_dataset(test_df, ae_name), **params)\n",
        "with open(f'{model_folder}/h_dims.pkl', 'rb') as f: h_dims = pickle.load(f)\n",
        "\n",
        "model = Classifier(in_dim, h_dims)\n",
        "if torch.cuda.is_available(): model = model.cuda()\n",
        "model_path_best_cohen = '/content/drive/MyDrive/Adverse-effect-prediction-main/best_models/nausea_cohen_0.4134078212290503.pt'\n",
        "\n",
        "# def eval(model, loader, path=None, device='cpu'):\n",
        "#     if path != None: load_model(model, path)\n",
        "#     performance, probs, label = train_epoch(model, loader, device=device)\n",
        "#     return performance, probs, label\n",
        "\n",
        "_ = eval(model, test_loader, path=model_path_best_cohen, device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "TPrwVRCYSeus",
        "outputId": "298e1a0b-9284-43af-a0d6-a3b5f4b18a77"
      },
      "outputs": [],
      "source": [
        "model_folder = 'best_models'\n",
        "ae_name = 'vomiting'\n",
        "\n",
        "_, _, test_df = get_data(ae_name)\n",
        "test_loader = DataLoader(tox_dataset(test_df, ae_name), **params)\n",
        "with open(f'{model_folder}/h_dims.pkl', 'rb') as f: h_dims = pickle.load(f)\n",
        "\n",
        "model = Classifier(in_dim, h_dims)\n",
        "if torch.cuda.is_available(): model = model.cuda()\n",
        "model_path_best_cohen = '/content/drive/MyDrive/Adverse-effect-prediction-main/best_models/vomiting_cohen_0.29735234215885953.pt'\n",
        "# def eval(model, loader, path=None, device='cpu'):\n",
        "#     if path != None: load_model(model, path)\n",
        "#     performance, probs, label = train_epoch(model, loader, device=device)\n",
        "#     return performance, probs, label\n",
        "\n",
        "_ = eval(model, test_loader, path=model_path_best_cohen, device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "_JJ0WAR16EfK",
        "outputId": "47f29e38-3c5e-4d34-d6f1-4b5d1759224e"
      },
      "outputs": [],
      "source": [
        "model_folder = 'best_models_3'\n",
        "ae_name = 'vomiting'\n",
        "\n",
        "_, _, test_df = get_data(ae_name)\n",
        "test_loader = DataLoader(tox_dataset(test_df, ae_name), **params)\n",
        "with open(f'{model_folder}/h_dims.pkl', 'rb') as f: h_dims = pickle.load(f)\n",
        "\n",
        "model = Classifier(in_dim, h_dims)\n",
        "if torch.cuda.is_available(): model = model.cuda()\n",
        "model_path_best_cohen = '/content/drive/MyDrive/Adverse-effect-prediction-main/best_models_3/vomiting_cohen_0.29735234215885953.pt'\n",
        "\n",
        "_ = eval(model, test_loader, path=model_path_best_cohen, device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDkSuNf76f-g"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
